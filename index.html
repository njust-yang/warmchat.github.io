<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Warm Chat: Diffuse Emotion-aware Interactive Talking Head Avatar with Tree-Structured Guidance</title>
  <link rel="icon" type="image/x-icon" href="static/images/WIS.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><span style="color: rgb(255, 105, 180);">W</span><span style="color: rgb(255, 223, 0);">a</span><span style="color: rgb(255, 182, 193);">r</span><span style="color: rgb(183, 110, 121);">m</span><span style="color: rgb(255, 127, 80);"> </span><span style="color: rgb(250,119,182);">C</span><span style="color: rgb(75, 54, 232);">h</span><span style="color: rgb(255, 127, 80);">a</span><span style="color: rgb(183, 110, 121);">t</span>:  Diffuse Emotion-aware Interactive Talking Head Avatar with Tree-Structured Guidance</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://njust-yang.github.io/" target="_blank">Haijie Yang<sup>1</sup></a>,
                <span class="author-block">
                  <a href="https://jessezhang92.github.io/" target="_blank">Zhenyu Zhang<sup>2</sup></a>,</span>
                  <span class="author-block">
                    <a href="https://xiantaohu.github.io/index.html" target="_blank">XianTao Hu<sup>1</sup></a>,
                  </span>
                  <span class="author-block">
                    <a href="https://ha0tang.github.io/" target="_blank">Hao Tang<sup>3</sup></a>,
                  </span>
                
                  <span class="author-block">
                    <a href="http://www.patternrecognition.asia/qian/" target="_blank">Jianjun Qian<sup>1</sup></a>,
                  </span>
                  <span class="author-block">
                    <a href="https://dblp.org/pid/y/JianYang3.html" target="_blank">Jian Yang<sup>1</sup></a>,</span>
                  </span>
                  </div>

                  <div class="is-size-2 publication-authors">
                    <span class="eql-cntrb"><small><br><sup>1</sup>Nanjing University of Science and Technology</small></span>
                    <span class="eql-cntrb"><small><br><sup>2</sup>Nanjing University</small></span>
                     <span class="eql-cntrb"><small><br><sup>3</sup>Peking University</small></span>
                  </div>
            
                  <div class="is-size-2 publication-authors">
                    <span class="author-block">Under Submission</span>

                  </div>


                    

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://njust-yang.github.io/warmchat.github.io/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code(Coming soon)</span>
                  </a>
                </span>
              
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://njust-yang.github.io/warmchat.github.io/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv(Coming soon)</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3">Results demo (Video size limit, compressed) </h2>
      <video preload="auto"poster="" id="tree" autoplay controls muted loop width="600px" outline="0px"> 
        <!-- Your video -->
<!--         <source src="pics/teaser.mp4" -->
        <source src="pics/demo_compress.mp4"
        type="video/mp4">
      </video>
      <!-- <h2 class="subtitle has-text-centered"> 
      </h2> -->
    </div>
  </div> 
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generative models have advanced rapidly, enabling impressive talking head generation that brings AI to life. However, most existing methods focus solely on one-way portrait animation. Even the few that support bidirectional conversational interactions lack precise emotion-adaptive capabilities, significantly limiting their practical applicability. In this paper, we propose EAI-Avatar, a novel emotion-aware talking head generation framework for dyadic interactions. Leveraging the dialogue generation capability of large language models (LLMs, e.g., GPT-4), our method produces temporally consistent virtual avatars with rich emotional variations that seamlessly transition between speaking and listening states. Specifically, we design a Transformer-based head mask generator that learns temporally consistent motion features in a latent mask space, capable of generating arbitrary-length, temporally consistent mask sequences to constrain head motions. Furthermore, we introduce an interactive talking tree structure to represent dialogue state transitions, where each tree node contains information such as child/parent/sibling nodes and the current character's emotional state. By performing reverse-level traversal, we extract rich historical emotional cues from the current node to guide expression synthesis. Extensive experiments demonstrate the superior performance and effectiveness of our method.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper poster -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Methodology</h2>
        <div class="has-text-centered">
          <img src="./pics/pipeline.png" alt="pipeline" style="max-width: 100%; height: auto;">
        </div>
        <h2 class="subtitle has-text-justified">
         First, we construct an Interactive Talking Tree (ITT) to represent the dynamic states of the dialogue throughout the modeling process. By performing a reverse hierarchical traversal with weighted operations on the ITT, we derive the cumulative emotional label at the current node. Additionally, we fine-tune the pre-trained audio-to-expression model to obtain the speaker's facial motion. Next, we introduce a Consistent Random Head Mask Generator (CRHMG) to regulate the head motion of both the speaker and the listener. We also develop a Listener Emotion-Expression Dictionary (LEED) that maps emotional labels to plausible facial expressions, which are then translated into corresponding facial motion. Finally, we design a diffusion model conditioned on both facial and head motion to generate realistic responses for the speaker and listener. Leveraging a large language model (GPT-4), the system supports continuous, open-ended dialogue between the two parties.
        </h2>
      </div>
    </div>
  </div>
</section>
<!--End paper poster -->

<section class="comparison">
  <div class="container is-max-desktop" style="text-align: center;">
    <div class="hero-body">
     <h2 class="title is-3">Introduction of ITT (Interactive Talking Tree)</h2>
      <video preload="auto"poster="" id="tree" autoplay controls muted loop width="600px" outline="0px"> 
        <!-- Your video -->
<!--         <source src="pics/ITT_compress.mp4" -->
        <source src="pics/ITT_compress.mp4"
        type="video/mp4">
      </video>
      <!-- <h2 class="subtitle has-text-centered"> 
      </h2> -->
    </div>
  </div> 
</section>

 
</section>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
    <script>
      window.addEventListener('DOMContentLoaded', (event) => {
        const videoWrappers = document.querySelectorAll('.video-wrapper');
      
        videoWrappers.forEach(wrapper => {
          const defaultVideo = wrapper.querySelector('.default-video');
          const aspectRatio = defaultVideo.videoWidth / defaultVideo.videoHeight;
          const height = wrapper.offsetWidth / aspectRatio;
      
          wrapper.style.height = `${height}px`;
      
          wrapper.addEventListener('mouseenter', () => {
            defaultVideo.pause();
            hoverVideo.play();
          });
      
          wrapper.addEventListener('mouseleave', () => {
            defaultVideo.play();
            hoverVideo.pause();
          });
        });
      }); 
      $(document).ready(function() {
        var carouselItems = $('.carousel .item');
        var numItems = carouselItems.length;
        var numVideos = 5;
        var currentIndex = 0;
    
        $('.carousel').on('click', function() {
          currentIndex++;
          if (currentIndex + numVideos <= numItems) {
            carouselItems.removeClass('active');
            carouselItems.slice(currentIndex, currentIndex + numVideos).addClass('active');
          } else {
            currentIndex = 0;
            carouselItems.removeClass('active');
            carouselItems.slice(currentIndex, currentIndex + numVideos).addClass('active');
          }
        });
    
        carouselItems.slice(currentIndex, currentIndex + numVideos).addClass('active');
      });
    </script>
  </body>
  </html>
